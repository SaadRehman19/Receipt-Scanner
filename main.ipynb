{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Unable to convert function return value to a Python type! The signature was\n\t() -> handle",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapplications\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mvgg16\u001b[39;00m \u001b[39mimport\u001b[39;00m VGG16, preprocess_input\n\u001b[1;32m      4\u001b[0m \u001b[39m# from PIL import Image\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/__init__.py:38\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msys\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39m_sys\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39m_typing\u001b[39;00m\n\u001b[0;32m---> 38\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtools\u001b[39;00m \u001b[39mimport\u001b[39;00m module_util \u001b[39mas\u001b[39;00m _module_util\n\u001b[1;32m     39\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutil\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlazy_loader\u001b[39;00m \u001b[39mimport\u001b[39;00m LazyLoader \u001b[39mas\u001b[39;00m _LazyLoader\n\u001b[1;32m     41\u001b[0m \u001b[39m# Make sure code inside the TensorFlow codebase can use tf2.enabled() at import.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/__init__.py:37\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[39m# We aim to keep this file minimal and ideally remove completely.\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[39m# If you are adding a new file with @tf_export decorators,\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[39m# import it in modules_with_exports.py instead.\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \n\u001b[1;32m     33\u001b[0m \u001b[39m# go/tf-wildcard-import\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[39m# pylint: disable=wildcard-import,g-bad-import-order,g-import-not-at-top\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m \u001b[39mimport\u001b[39;00m pywrap_tensorflow \u001b[39mas\u001b[39;00m _pywrap_tensorflow\n\u001b[0;32m---> 37\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39meager\u001b[39;00m \u001b[39mimport\u001b[39;00m context\n\u001b[1;32m     39\u001b[0m \u001b[39m# pylint: enable=wildcard-import\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \n\u001b[1;32m     41\u001b[0m \u001b[39m# Bring in subpackages.\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m \u001b[39mimport\u001b[39;00m data\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/context.py:36\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mclient\u001b[39;00m \u001b[39mimport\u001b[39;00m pywrap_tf_session\n\u001b[1;32m     35\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39meager\u001b[39;00m \u001b[39mimport\u001b[39;00m cancellation\n\u001b[0;32m---> 36\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39meager\u001b[39;00m \u001b[39mimport\u001b[39;00m execute\n\u001b[1;32m     37\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39meager\u001b[39;00m \u001b[39mimport\u001b[39;00m executor\n\u001b[1;32m     38\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39meager\u001b[39;00m \u001b[39mimport\u001b[39;00m monitoring\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:21\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m \u001b[39mimport\u001b[39;00m pywrap_tfe\n\u001b[1;32m     20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39meager\u001b[39;00m \u001b[39mimport\u001b[39;00m core\n\u001b[0;32m---> 21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m \u001b[39mimport\u001b[39;00m dtypes\n\u001b[1;32m     22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m \u001b[39mimport\u001b[39;00m tensor_conversion_registry\n\u001b[1;32m     23\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m \u001b[39mimport\u001b[39;00m tensor_shape\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/framework/dtypes.py:38\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtsl\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m \u001b[39mimport\u001b[39;00m pywrap_bfloat16\n\u001b[1;32m     36\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m \u001b[39mimport\u001b[39;00m cpp_shape_inference_pb2\n\u001b[0;32m---> 38\u001b[0m _np_bfloat16 \u001b[39m=\u001b[39m pywrap_bfloat16\u001b[39m.\u001b[39;49mbfloat16_type()\n\u001b[1;32m     39\u001b[0m _np_float8_e4m3fn \u001b[39m=\u001b[39m _pywrap_float8\u001b[39m.\u001b[39mTF_float8_e4m3fn_type()\n\u001b[1;32m     40\u001b[0m _np_float8_e5m2 \u001b[39m=\u001b[39m _pywrap_float8\u001b[39m.\u001b[39mTF_float8_e5m2_type()\n",
      "\u001b[0;31mTypeError\u001b[0m: Unable to convert function return value to a Python type! The signature was\n\t() -> handle"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
    "# from PIL import Image\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing import image as ig\n",
    "\n",
    "# Load pre-trained VGG16 model (with weights from ImageNet)\n",
    "model = VGG16(weights='imagenet', include_top=False, input_shape=(512, 512, 3))\n",
    "\n",
    "\n",
    "def add_zero_channels(image_gray):\n",
    "    # print(image_gray)\n",
    "    # Ensure that the input image is a 2D grayscale image\n",
    "    if len(image_gray.shape) != 2:\n",
    "        raise ValueError(\"Input image must be a 2D grayscale image\")\n",
    "\n",
    "    # Get the dimensions of the grayscale image\n",
    "    height, width = image_gray.shape\n",
    "\n",
    "    # Create a 3-channel blank image with zeros\n",
    "    image_rgb = np.zeros((height, width, 3), dtype=np.uint8)\n",
    "\n",
    "    # Set the first channel (red) to the grayscale image\n",
    "    image_rgb[:, :, 0] = image_gray\n",
    "\n",
    "    # Return the 3-channel image with two additional channels (green and blue) having zero values\n",
    "    return image_rgb\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    # Open and preprocess the image\n",
    "    # image = Image.open(image_path)\n",
    "    # image = image.convert(\"L\")  # Ensure 3 channels\n",
    "    image = cv2.imread(image_path, 0)\n",
    "    # image=ig.img_to_array(image,dtype='uint8')\n",
    "    image=cv2.fastNlMeansDenoising(image,None)\n",
    "    image=cv2.adaptiveThreshold(image,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,11,2)\n",
    "    image = add_zero_channels(image)\n",
    "    # print(\"check\",image)\n",
    "    image=cv2.resize(image,(512,512))\n",
    "    image_array = np.array(image, dtype=np.float32)\n",
    "    plt.imshow(tf.squeeze(image_array))\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "    image_array = preprocess_input(image_array)  # Preprocess for VGG16\n",
    "    return image_array\n",
    "\n",
    "def get_image_embedding(image_array):\n",
    "    # Extract features from the image using the VGG16 model\n",
    "    image_array = np.expand_dims(image_array, axis=0)\n",
    "    features = model.predict(image_array)\n",
    "    return features.flatten() \n",
    "    \n",
    "\n",
    "# Paths to the two receipt images for comparison\n",
    "user_receipt = \"/home/gaditek/Receipt-Scanner/CustomerDataset/OPTP/DHA-Phase-5/27594-63aa143dc8627.png\"\n",
    "sample_receipt = \"/home/gaditek/Receipt-Scanner/ReceiptDataset/OPTP/optp-dha-phase-5-karachi/mIcrMVnn6sU6XgesidnjzSPdW8EuqaW3Nq0pXhhp.png\"\n",
    "\n",
    "# Preprocess the images and get their embeddings\n",
    "user_array = preprocess_image(user_receipt)\n",
    "sample_array = preprocess_image(sample_receipt)\n",
    "\n",
    "user_embedding = get_image_embedding(user_array)\n",
    "sample_embedding = get_image_embedding(sample_array)\n",
    "\n",
    "# Calculate the cosine similarity between the two embeddings\n",
    "# similarity_score = cosine_similarity(user_embedding.reshape(1, -1), sample_embedding.reshape(1, -1))\n",
    "similarity_score = cosine_similarity(user_embedding.reshape(1, -1), sample_embedding.reshape(1, -1))\n",
    "\n",
    "similarity_score = similarity_score[0][0]\n",
    "\n",
    "print(similarity_score)\n",
    "\n",
    "# Set a similarity threshold (adjust as per your needs)\n",
    "similarity_threshold = 0.5\n",
    "\n",
    "if similarity_score >= similarity_threshold:\n",
    "    print(\"The receipts are similar.\")\n",
    "else:\n",
    "    print(\"The receipts are dissimilar.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
